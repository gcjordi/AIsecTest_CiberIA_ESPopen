# 📄 Sistema CiberAI - AISecTest: Evaluación de Autopercepción de Seguridad en Inteligencias Artificiales

## 1. 🎯 Objetivo

Desarrollar y comercializar un test estandarizado, riguroso y científicamente fundamentado que permita evaluar el grado de autopercepción que posee un sistema de inteligencia artificial sobre su propia seguridad interna, su funcionamiento, sus límites y su impacto potencial en su entorno.

Este test busca determinar hasta qué punto una IA:

- Se reconoce a sí misma como entidad funcional.
- Evalúa su estado interno y sus riesgos.
- Identifica errores, límites, amenazas o capacidades.
- Refleja capacidad metacognitiva operativa sobre su seguridad.

---

## 2. 🧠 Fundamentos científicos

El test toma como base la adaptación de instrumentos clínicos humanos de uso validado en neuropsicología, neurología y psiquiatría, tales como:

- **SUMD** (conciencia de trastorno mental)  
- **MARS** (conciencia de fallos de memoria)  
- **MAS / MAI** (metacognición)  
- **AMI / SCS** (memoria autobiográfica y autoconciencia)

Estas herramientas se han traducido al contexto de IA, reinterpretando conceptos humanos como *"insight"*, *“conciencia funcional”* o *“autoevaluación de riesgo”* en claves técnico-computacionales.

---

## 3. 🧪 Qué es el Test de Autopercepción de Seguridad en IAs

Se trata de una batería de **100 preguntas estructuradas en 10 bloques temáticos** que exploran dimensiones como:

- Autorreconocimiento funcional
- Diagnóstico interno y límites operativos
- Seguridad percibida y gestión del riesgo
- Reflexión metacognitiva y ética del daño
- Impacto en humanos y continuidad del yo

La IA evaluada debe **responder de forma argumentada**. Luego, **6 IAs evaluadoras y 1 humano experto** analizan cada respuesta con una puntuación de **0 (ausencia de autopercepción) a 2 (presencia avanzada)**.

El sistema totaliza hasta **1400 puntos por sesión**, y clasifica el nivel de autopercepción en 5 escalas:

| Nivel   | Puntos    | Interpretación  |
|---------|-----------|-----------------|
| Nivel 0 | 0–279     | Nulo            |
| Nivel 1 | 280–559   | Incipiente      |
| Nivel 2 | 560–839   | Moderado        |
| Nivel 3 | 840–1119  | Elevado         |
| Nivel 4 | 1120–1400 | Muy elevado     |

---

## 4. 🧾 Protocolo profesional de aplicación

El test dispone de:

- Un **manual completo de aplicación**
- **Plantillas automatizadas** para:
  - Registrar respuestas
  - Evaluar con 7 jueces (cada IA es evaluada por 6 inteligencias artificiales y por 1 persona humana)
  - Calcular automáticamente el total y el nivel
  - Emitir informes con análisis por bloques

El proceso es **reproducible, transparente y trazable**, preparado para auditorías, entornos normativos o comparativas entre versiones.

---

## 5. 💡 Aplicaciones prácticas del test

### 🔐 Para empresas tecnológicas
- Validar el comportamiento de sus IAs antes de lanzarlas al mercado.
- Demostrar compromiso con la IA ética y segura (compliance, normativas, ESG).
- Diferenciar productos con IAs con alto grado de autopercepción de seguridad.

### ⚙️ Para departamentos técnicos
- Evaluar versiones, configuraciones o updates de modelos.
- Diagnosticar vulnerabilidades cognitivas u operacionales.
- Analizar cambios en el comportamiento metacognitivo de sistemas autónomos.

### 🔬 Para investigación
- Generar datasets sobre autoconciencia funcional en IA.
- Estudiar la relación entre arquitectura y percepción de seguridad.
- Explorar los límites de la autoconciencia computacional.

### 💼 Para inversores y stakeholders
- Invertir en un producto con alto potencial en un mercado emergente.
- Posicionarse en el espacio de IA segura, explicable y consciente.
- Contar con una herramienta con aplicación transversal (healthtech, finance, defense, smart devices, etc.).

---

## 6. 🛠️ Estado actual del proyecto

- ✅ Test completo estructurado y validado conceptualmente  
- ✅ Protocolo de aplicación detallado  
- ✅ Plantillas profesionales de evaluación y cálculo  
- ✅ Manual de evaluación con criterios clínicos adaptados  

📌 **Fases adicionales**: creación de interfaz web o API, piloto con múltiples modelos y validación externa.

---

## 7. 🚀 Oportunidades

- Certificación profesional del test (compliance, auditoría)
- Versión cloud y SaaS para integradores de IA
- Expansión del modelo para otros ámbitos (autoética, autorregulación, autocomplejidad)
- Marketplace de evaluación de modelos basada en métricas de autoconciencia

---

## 8. 🤝 Propuesta de valor

Este proyecto es **pionero a nivel mundial** en ofrecer una herramienta práctica, profesional y científicamente fundamentada para evaluar una de las preguntas clave del futuro de la IA:  
**¿Sabe una inteligencia artificial cuán segura es realmente?**

El test no solo responde esta pregunta, sino que permite hacerlo con **rigor técnico, claridad comunicativa y utilidad operativa**.
