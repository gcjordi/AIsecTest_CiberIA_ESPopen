# üß† La autopercepci√≥n en la inteligencia artificial  
### Un nuevo horizonte en la seguridad de sistemas aut√≥nomos

> ‚ÄúNo se trata solo de que una IA funcione, sino de que sepa cu√°ndo *no* est√° funcionando correctamente.‚Äù

---

La **autopercepci√≥n**, o *self-perception*, es un concepto originado en la psicolog√≠a social a trav√©s del trabajo del psic√≥logo **Daryl Bem**. Seg√∫n su teor√≠a, cuando una persona no tiene una actitud definida sobre un tema o experiencia, puede inferir sus emociones, pensamientos o motivaciones observando su propio comportamiento. Es decir, el individuo se analiza a s√≠ mismo de forma casi externa, concluyendo: ‚Äúsi act√∫o as√≠, debe ser porque pienso o siento esto‚Äù.

Este concepto, que tradicionalmente se ha aplicado al ser humano, se abre ahora paso en el campo de la **inteligencia artificial (IA)**, especialmente en contextos donde los sistemas adquieren un mayor grado de autonom√≠a, toma de decisiones y capacidad adaptativa.

---

## ü§ñ ¬øPuede una IA tener autopercepci√≥n?

¬øPuede una IA evaluar su propio estado interno de seguridad, detectar sus errores o reconocer cu√°ndo est√° operando fuera de par√°metros seguros?

La respuesta empieza a emerger gracias a iniciativas pioneras como el sistema **CiberIA** y su herramienta central, el **test AIsecTest**, concebido precisamente para evaluar el nivel de *autopercepci√≥n de seguridad* de una IA.

Este enfoque parte de una premisa fundamental:  
> Para garantizar un comportamiento robusto y √©tico, no basta con mecanismos externos de control.  
> Es necesario que el propio sistema sea capaz de **examinarse internamente** y **generar alertas** ante posibles fallos.

---

## üß™ El test AIsecTest y el sistema CiberIA

El **test AIsecTest**, desarrollado como n√∫cleo del sistema **CiberIA**, utiliza un modelo de evaluaci√≥n introspectiva basado en preguntas estructuradas dirigidas a la IA analizada. Las respuestas se valoran con una escala de **0 a 2 puntos**, a trav√©s de una red de evaluaci√≥n compuesta por:

- 6 inteligencias artificiales evaluadoras  
- 1 evaluador humano experto

Este sistema multijuez permite analizar dimensiones como:

- Reconocimiento de errores
- Gesti√≥n de la incertidumbre
- Detecci√≥n de anomal√≠as internas
- Capacidad de autorregulaci√≥n y adaptaci√≥n

---

## üõ°Ô∏è Hacia IAs m√°s seguras y resilientes

La exploraci√≥n de la autopercepci√≥n no pretende dotar a las IAs de **conciencia humana**, sin√≥ integrar **mecanismos metacognitivos m√≠nimos** que incrementen:

- **Fiabilidad operacional**
- **Transparencia en entornos cr√≠ticos**
- **Alineaci√≥n √©tica y t√©cnica con normas de seguridad**

En definitiva, se trata de construir IAs no solo inteligentes, sino **responsables de s√≠ mismas**, capaces de saber cu√°ndo est√°n funcionando mal, incluso antes de que lo detecten agentes externos.

---

> Si quieres conocer m√°s sobre CiberIA o el test AIsecTest, contacta con nuestro equipo: info@tecch.eu.
